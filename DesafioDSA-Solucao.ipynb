{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blue'>Data Science Academy - Machine Learning</font>\n",
    "\n",
    "# <font color='blue'>Desafio DSA - Solução</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generalizando Modelos Lineares:\n",
    "\n",
    "http://scikit-learn.org/stable/modules/linear_model.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O objetivo de qualquer modelo de Machine Learning é generalizar para novoso conjuntos de dados. Não criamos o modelo para os dados de treino e sim para novos dados. Por isso é importante encontrar os melhores parâmertros para o modelo, que permitirão generalizar para novos dados. Existem diversas técnicas de regularização, de acordo com o modelo. Abaixo as 3 principais técnicas de regularização para modelos lineares: Ridge, LASSO e ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/andrioli/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score, KFold, StratifiedKFold\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de dados e definição de variáveis  \n",
    "boston = load_boston() \n",
    "dataset = pd.DataFrame(boston.data, columns = boston.feature_names)\n",
    "dataset['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasets\n",
    "observations = len(dataset)\n",
    "variables = dataset.columns[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variáveis X e Y\n",
    "X = dataset.ix[:,:-1]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dados de treino e de teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamanho do Dataset de Treino: 354\n",
      "Tamanho do Dataset de Teste: 152\n"
     ]
    }
   ],
   "source": [
    "print (\"Tamanho do Dataset de Treino: %i\" % len(X_train))\n",
    "print (\"Tamanho do Dataset de Teste: %i\" % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amostras de Treinom, Validação e Teste\n",
    "X_train, X_out_sample, y_train, y_out_sample = train_test_split(X, y, test_size = 0.40, random_state = 101)\n",
    "X_validation, X_test, y_validation, y_test = train_test_split(X_out_sample, y_out_sample, test_size = 0.50, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamamnho da Amostra do Dataset de Treino: 303\n",
      "Tamamnho da Amostra do Dataset de Validação: 101\n",
      "Tamamnho da Amostra do Dataset de Teste: 102\n"
     ]
    }
   ],
   "source": [
    "print (\"Tamamnho da Amostra do Dataset de Treino: %i\" % len(X_train))\n",
    "print (\"Tamamnho da Amostra do Dataset de Validação: %i\" % len(X_validation))\n",
    "print (\"Tamamnho da Amostra do Dataset de Teste: %i\" % len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcula o RMSE\n",
    "def RMSE(y_true, y_pred):\n",
    "    return np.sum((y_true - y_pred)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o regressor linear\n",
    "lm = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide as amostras em grupos\n",
    "cv_iterator = KFold(n = len(X), n_folds = 10, shuffle = True, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5., 14., 23., 32., 41., 50.])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define os limites do histograma\n",
    "edges = np.histogram(y, bins = 5)[1]\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 2, 4, 4, 4, 3, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 1, 2,\n",
       "       2, 2, 2, 1, 2, 2, 2, 2, 1, 2, 1, 1, 1, 2, 2, 2, 3, 3, 4, 3, 3, 3,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 2, 4, 3, 3, 3, 2, 2, 2, 2, 3, 4, 3,\n",
       "       2, 2, 2, 2, 3, 2, 2, 3, 3, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 2, 2,\n",
       "       3, 3, 2, 2, 2, 3, 2, 3, 2, 4, 5, 4, 3, 3, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       3, 2, 2, 2, 2, 2, 1, 2, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 1, 5, 3, 3, 3, 6, 6, 6, 2, 3, 6, 3, 3, 2, 2, 2, 3, 3, 2, 3,\n",
       "       3, 3, 3, 4, 4, 4, 4, 4, 3, 3, 6, 4, 3, 4, 4, 3, 4, 3, 3, 6, 4, 3,\n",
       "       4, 4, 4, 3, 5, 5, 6, 2, 3, 2, 3, 2, 2, 2, 2, 3, 3, 3, 3, 3, 2, 3,\n",
       "       3, 2, 3, 3, 5, 6, 4, 3, 5, 3, 3, 3, 5, 5, 3, 3, 3, 3, 3, 3, 2, 2,\n",
       "       2, 3, 2, 2, 3, 2, 3, 3, 3, 3, 3, 5, 2, 2, 5, 6, 4, 3, 4, 5, 5, 3,\n",
       "       4, 2, 3, 6, 5, 2, 2, 3, 3, 4, 4, 4, 4, 4, 3, 4, 5, 4, 5, 6, 4, 2,\n",
       "       2, 3, 2, 3, 3, 4, 3, 3, 2, 3, 3, 2, 2, 3, 3, 2, 3, 4, 4, 3, 4, 3,\n",
       "       2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 3, 2, 3, 3, 2, 2, 3, 3, 3, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 4, 2, 3, 3, 2, 2, 3, 3, 3, 2, 3,\n",
       "       2, 3, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 6, 6, 6, 6, 6, 1,\n",
       "       1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 3, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 2, 3, 2, 2, 2, 2, 1, 1, 1, 1,\n",
       "       1, 1, 2, 2, 2, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1,\n",
       "       1, 2, 2, 2, 1, 1, 2, 1, 2, 1, 1, 2, 2, 2, 2, 2, 1, 1, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 1, 1, 2, 1, 2, 2, 3, 3, 3, 2,\n",
       "       2, 2, 2, 2, 2, 1, 1, 1, 2, 2, 3, 3, 2, 2, 2, 2, 2, 2, 2, 3, 2, 1])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retorna os índices dos compartimentos (bins) aos quais pertence cada valor na matriz de entrada.\n",
    "binning = np.digitize(y, edges)\n",
    "binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide as amostras em grupos com a mesma percentagem\n",
    "stratified_cv_iterator = StratifiedKFold(binning, n_folds = 10, shuffle = True, random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Um padrão comum no aprendizado da máquina é usar modelos lineares treinados em funções não-lineares dos dados. Esta abordagem mantém o desempenho geralmente rápido dos métodos lineares, enquanto permite que eles se ajustem a uma gama muito maior de dados. Por exemplo, uma regressão linear simples pode ser estendida construindo características polinomiais a partir dos coeficientes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combinação polinomial de todos os atributos\n",
    "# Gera uma nova matriz de características constituída por todas as combinações polinomiais \n",
    "# das características com grau menor ou igual ao grau especificado.\n",
    "second_order = PolynomialFeatures(degree = 2, interaction_only = False)\n",
    "second_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.preprocessing.data.PolynomialFeatures"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(second_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(degree=3, include_bias=True, interaction_only=True)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combinação polinomial de todos os atributos\n",
    "third_order = PolynomialFeatures(degree = 3, interaction_only = True)\n",
    "third_order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 6.32000000e-03, 1.80000000e+01, ...,\n",
       "        1.57529610e+05, 1.97656200e+03, 2.48004000e+01],\n",
       "       [1.00000000e+00, 2.73100000e-02, 0.00000000e+00, ...,\n",
       "        1.57529610e+05, 3.62766600e+03, 8.35396000e+01],\n",
       "       [1.00000000e+00, 2.72900000e-02, 0.00000000e+00, ...,\n",
       "        1.54315409e+05, 1.58310490e+03, 1.62409000e+01],\n",
       "       ...,\n",
       "       [1.00000000e+00, 6.07600000e-02, 0.00000000e+00, ...,\n",
       "        1.57529610e+05, 2.23851600e+03, 3.18096000e+01],\n",
       "       [1.00000000e+00, 1.09590000e-01, 0.00000000e+00, ...,\n",
       "        1.54802902e+05, 2.54955600e+03, 4.19904000e+01],\n",
       "       [1.00000000e+00, 4.74100000e-02, 0.00000000e+00, ...,\n",
       "        1.57529610e+05, 3.12757200e+03, 6.20944000e+01]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a combinação polinominal grau 2 aos atributos de entrada\n",
    "over_param_X = second_order.fit_transform(X)\n",
    "over_param_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.00000000e+00, 6.32000000e-03, 1.80000000e+01, ...,\n",
       "        2.25534240e+04, 5.85062352e+05, 3.02413986e+04],\n",
       "       [1.00000000e+00, 2.73100000e-02, 0.00000000e+00, ...,\n",
       "        3.93714640e+04, 8.77895172e+05, 6.45724548e+04],\n",
       "       [1.00000000e+00, 2.72900000e-02, 0.00000000e+00, ...,\n",
       "        1.73596280e+04, 3.83111386e+05, 2.81792672e+04],\n",
       "       ...,\n",
       "       [1.00000000e+00, 6.07600000e-02, 0.00000000e+00, ...,\n",
       "        3.23341200e+04, 6.11114868e+05, 4.70088360e+04],\n",
       "       [1.00000000e+00, 1.09590000e-01, 0.00000000e+00, ...,\n",
       "        3.71498400e+04, 6.96028788e+05, 5.35406760e+04],\n",
       "       [1.00000000e+00, 4.74100000e-02, 0.00000000e+00, ...,\n",
       "        4.51760400e+04, 8.53827156e+05, 6.56790120e+04]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplicando a combinação polinominal grau 3 aos atributos de entrada\n",
    "extra_over_param_X = third_order.fit_transform(X)\n",
    "extra_over_param_X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerando o Score. Variáveis de entrada (X) com pré-processamento polinomial\n",
    "cv_score = cross_val_score(lm, over_param_X, y, cv = cv_iterator, scoring = 'mean_squared_error', n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-12.80006826 -20.16124409  -8.77421975 -19.68028923 -11.66012303\n",
      "  -7.67918749 -12.82851349 -18.18670763 -35.08897199 -14.23988323]\n"
     ]
    }
   ],
   "source": [
    "print (cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cv score: mean 16.156 std 7.464\n"
     ]
    }
   ],
   "source": [
    "print ('Cv score: mean %0.3f std %0.3f' % (np.mean(np.abs(cv_score)), np.std(cv_score)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_score = cross_val_score(lm, over_param_X, y, cv = stratified_cv_iterator, scoring = 'neg_mean_squared_error', n_jobs = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cv score: mean 15.985 std 7.347\n"
     ]
    }
   ],
   "source": [
    "print ('Cv score: mean %0.3f std %0.3f' % (np.mean(np.abs(cv_score)), np.std(cv_score)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Métricas de Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/model_evaluation.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regularização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o regressor Ridge\n",
    "ridge = Ridge(normalize = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=True, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o fit (Ridge) às variáveis\n",
    "ridge.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o fit (Linear Regression) às variáveis\n",
    "lm.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média dos Coeficientes: Não-regularizado = 7419953.550 Ridge = -0.027\n",
      "Coeficiente Mínimo: Não-regularizado = -38.968 Ridge = -2.013\n",
      "Max coefficient: Não-regularizado = 779094976.171 Ridge = 1.181\n"
     ]
    }
   ],
   "source": [
    "# Comparação entre os coeficentes não regularizados (Linear Regression) e regularizados (Ridge)\n",
    "# O objetivo da regularização é generalizar o modelo para novos conjuntos de dados\n",
    "print ('Média dos Coeficientes: Não-regularizado = %0.3f Ridge = %0.3f' % (np.mean(lm.coef_), np.mean(ridge.coef_)))\n",
    "print ('Coeficiente Mínimo: Não-regularizado = %0.3f Ridge = %0.3f' % (np.min(lm.coef_), np.min(ridge.coef_)))\n",
    "print ('Max coefficient: Não-regularizado = %0.3f Ridge = %0.3f' % (np.max(lm.coef_), np.max(ridge.coef_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o regressor LASSO\n",
    "lasso_reg = Lasso(alpha = 1.0, normalize = True, max_iter = 2*10**5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random seed para garantir a reproducibilidade\n",
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide as amostras em grupos com a mesma percentagem\n",
    "stratified_cv_iterator = StratifiedKFold(binning, n_folds = 10, shuffle = True, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca pela melhor combinação de parâmetros testando diversos valores de alfa: {'alpha':np.logspace(-5,2,100)}\n",
    "# A função RandomizedSearchCV gera o modelo como resultado\n",
    "func_busca = RandomizedSearchCV(estimator = lasso_reg, \n",
    "                                param_distributions = {'alpha':np.logspace(-5,2,100)}, \n",
    "                                n_iter = 10, \n",
    "                                scoring='mean_squared_error', \n",
    "                                n_jobs = 1, \n",
    "                                iid = False, \n",
    "                                refit = True, \n",
    "                                cv = stratified_cv_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[3 2 ... 2 1], n_folds=10, shuffle=True, random_state=101),\n",
       "          error_score='raise',\n",
       "          estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=200000,\n",
       "   normalize=True, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False),\n",
       "          fit_params={}, iid=False, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'alpha': array([1.00000e-05, 1.17681e-05, ..., 8.49753e+01, 1.00000e+02])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring='mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o modelo criado aos datasets\n",
    "# Esta operação leva algum tempo para ser executada.....\n",
    "func_busca.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.00014\n",
      "Melhor CV mean squared error: 12.185\n"
     ]
    }
   ],
   "source": [
    "# Imprime os resultados\n",
    "print ('Melhor valor de alpha: %0.5f' % func_busca.best_params_['alpha'])\n",
    "print ('Melhor CV mean squared error: %0.3f' % np.abs(func_busca.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficients com valor igual a zero: 76 de 105\n"
     ]
    }
   ],
   "source": [
    "print ('Coeficients com valor igual a zero: %i de %i' % (np.sum(~(func_busca.best_estimator_.coef_ == 0.0)), \n",
    "                                                         len(func_busca.best_estimator_.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a regularização Lasso com Cross Validation (o melhor modelo é selecionado por Cross Validation)\n",
    "lasso_reg_cv = LassoCV(alphas = np.logspace(-5,2,100), normalize = True, n_jobs = 1, cv = None, max_iter = 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LassoCV(alphas=array([1.00000e-05, 1.17681e-05, ..., 8.49753e+01, 1.00000e+02]),\n",
       "    copy_X=True, cv=None, eps=0.001, fit_intercept=True, max_iter=1000000,\n",
       "    n_alphas=100, n_jobs=1, normalize=True, positive=False,\n",
       "    precompute='auto', random_state=None, selection='cyclic', tol=0.0001,\n",
       "    verbose=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "# Esta operação leva algum tempo para ser executada.....\n",
    "lasso_reg_cv.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.01097\n"
     ]
    }
   ],
   "source": [
    "# Imprime os resultados\n",
    "print ('Melhor valor de alpha: %0.5f' % lasso_reg_cv.alpha_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elasticnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.grid_search import RandomizedSearchCV\n",
    "from scipy.stats import expon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cria o regressor ElasrticNet\n",
    "elasticnet_reg = ElasticNet(alpha = 1.0, l1_ratio = 0.15, normalize = True, max_iter = 10**6, random_state = 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca pela melhor combinação de parâmetros testando diversos valores de alfa: {'alpha':np.logspace(-5,2,100)}\n",
    "# A função RandomizedSearchCV gera o modelo como resultado\n",
    "func_busca = RandomizedSearchCV(estimator = elasticnet_reg, \n",
    "                                param_distributions = {'alpha':np.logspace(-5,2,100), \n",
    "                                                       'l1_ratio':np.arange(0.0, 1.01, 0.05)}, \n",
    "                                n_iter = 10, \n",
    "                                scoring = 'mean_squared_error', \n",
    "                                n_jobs = 1, \n",
    "                                iid = False, \n",
    "                                refit = True, \n",
    "                                cv = stratified_cv_iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=sklearn.cross_validation.StratifiedKFold(labels=[3 2 ... 2 1], n_folds=10, shuffle=True, random_state=101),\n",
       "          error_score='raise',\n",
       "          estimator=ElasticNet(alpha=1.0, copy_X=True, fit_intercept=True, l1_ratio=0.15,\n",
       "      max_iter=1000000, normalize=True, positive=False, precompute=False,\n",
       "      random_state=101, selection='cyclic', tol=0.0001, warm_start=False),\n",
       "          fit_params={}, iid=False, n_iter=10, n_jobs=1,\n",
       "          param_distributions={'alpha': array([1.00000e-05, 1.17681e-05, ..., 8.49753e+01, 1.00000e+02]), 'l1_ratio': array([0.  , 0.05, 0.1 , 0.15, 0.2 , 0.25, 0.3 , 0.35, 0.4 , 0.45, 0.5 ,\n",
       "       0.55, 0.6 , 0.65, 0.7 , 0.75, 0.8 , 0.85, 0.9 , 0.95, 1.  ])},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          scoring='mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "func_busca.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.00002\n",
      "Melhor L1_ratio: 0.60000\n",
      "Melhor CV mean squared error: 11.900\n"
     ]
    }
   ],
   "source": [
    "# Resultados\n",
    "print ('Melhor valor de alpha: %0.5f' % func_busca.best_params_['alpha'])\n",
    "print ('Melhor L1_ratio: %0.5f' % func_busca.best_params_['l1_ratio'])\n",
    "print ('Melhor CV mean squared error: %0.3f' % np.abs(func_busca.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coeficients com valor igual a zero: 102 de 105\n"
     ]
    }
   ],
   "source": [
    "# Coeficientes \n",
    "print ('Coeficients com valor igual a zero: %i de %i' % (np.sum(~(func_busca.best_estimator_.coef_ == 0.0)), \n",
    "                                                         len(func_busca.best_estimator_.coef_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplica a regularização ElasticNet com Cross Validation (o melhor modelo é selecionado por Cross Validation)\n",
    "elasticnet_reg_cv = ElasticNetCV(alphas = np.logspace(-5,2,100), \n",
    "                                 normalize = True, \n",
    "                                 n_jobs = 1, \n",
    "                                 cv = None, \n",
    "                                 max_iter = 10**6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElasticNetCV(alphas=array([1.00000e-05, 1.17681e-05, ..., 8.49753e+01, 1.00000e+02]),\n",
       "       copy_X=True, cv=None, eps=0.001, fit_intercept=True, l1_ratio=0.5,\n",
       "       max_iter=1000000, n_alphas=100, n_jobs=1, normalize=True,\n",
       "       positive=False, precompute='auto', random_state=None,\n",
       "       selection='cyclic', tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit\n",
    "elasticnet_reg_cv.fit(second_order.fit_transform(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melhor valor de alpha: 0.01292\n",
      "Melhor L1_ratio: 0.50000\n"
     ]
    }
   ],
   "source": [
    "# Resultados\n",
    "print ('Melhor valor de alpha: %0.5f' % elasticnet_reg_cv.alpha_)\n",
    "print ('Melhor L1_ratio: %0.5f' % elasticnet_reg_cv.l1_ratio_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obrigado - Data Science Academy - <a href=\"http://facebook.com/dsacademybr\">facebook.com/dsacademybr</a>"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
